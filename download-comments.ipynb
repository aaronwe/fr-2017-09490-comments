{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create database and tables\n",
    "\n",
    "# PostgreSQL 9.x\n",
    "# 1. create user with credentials in db_settings.py\n",
    "# 2. run query below manually (e.g. using psql)\n",
    "\"\"\"\n",
    "CREATE DATABASE benm\n",
    "    WITH \n",
    "    ENCODING = 'UTF8'\n",
    "    CONNECTION LIMIT = -1;\n",
    "CREATE USER benmuser WITH PASSWORD 'Ki3nslkj4nb';\n",
    "GRANT ALL ON DATABASE benm TO benmuser;\n",
    "\\connect benm\n",
    "ALTER SCHEMA public OWNER TO benmuser;\n",
    "ALTER DATABASE benm OWNER TO benmuser;\n",
    "ALTER DEFAULT PRIVILEGES \n",
    "    FOR USER benmuser\n",
    "    IN SCHEMA public\n",
    "    GRANT SELECT, INSERT, UPDATE, DELETE ON TABLES TO benmuser;\n",
    "    \n",
    "\"\"\"   \n",
    "\n",
    "\n",
    "# create the comments table. uncomment the execute line below and run\n",
    "# to do: create the attachments table\n",
    "import db_settings\n",
    "import psycopg2\n",
    "\n",
    "query = \"\"\"\n",
    "DROP TABLE IF EXISTS comments CASCADE;\n",
    "CREATE TABLE comments\n",
    "(\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    document_id VARCHAR UNIQUE,\n",
    "    tracking_number VARCHAR UNIQUE,\n",
    "    date_posted DATE,\n",
    "    retrieved TIMESTAMP,\n",
    "    has_attachments BOOLEAN DEFAULT FALSE,\n",
    "    comment TEXT\n",
    ");\n",
    "CREATE INDEX idx_document_id ON comments(document_id);\n",
    "CREATE INDEX idx_date ON comments(date_posted);\n",
    "\"\"\"\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(\n",
    "        database=db_settings.DB,\n",
    "        user=db_settings.USER,\n",
    "        password=db_settings.PASSWD,\n",
    "        host=db_settings.HOST)\n",
    "with conn:\n",
    "    with conn.cursor() as curs:\n",
    "        # curs.execute(query) # uncomment this line to create the table\n",
    "        # print(curs.statusmessage)\n",
    "    \n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to do: handle errors for duplicate keys\n",
    "# to do: download attachments\n",
    "# to do: incorporate ignore list into database\n",
    "\n",
    "import db_settings\n",
    "import psycopg2\n",
    "import os, errno, csv\n",
    "\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from dateutil.parser import parse\n",
    "from datetime import date\n",
    "\n",
    "ignore_list = []\n",
    "\n",
    "def get_comment(driver, url, source_document_id):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        element = WebDriverWait(driver, 10).until(\n",
    "            EC.title_is(\"Regulations.gov - Comment\")\n",
    "        )\n",
    "\n",
    "        element = driver.find_element(By.XPATH, '/html/body/div[3]/div[2]/div[2]/div[3]/div/table/tbody/tr/td[3]/div/div/div[2]/div[1]/div[1]/span[2]')\n",
    "        document_id = element.text\n",
    "        assert document_id == source_document_id # make sure the page matches\n",
    "        element = driver.find_element(By.XPATH, '/html/body/div[3]/div[2]/div[2]/div[3]/div/table/tbody/tr/td[3]/div/div/div[2]/div[1]/div[2]/span[2]')\n",
    "        tracking_number = element.text\n",
    "        element = driver.find_element(By.XPATH, '/html/body/div[3]/div[2]/div[2]/div[3]/div/table/tbody/tr/td[3]/div/div/div[2]/div[4]/div/div/span[2]')\n",
    "        d = parse(element.text)\n",
    "        date_posted = date(d.year, d.month, d.day)\n",
    "        element = driver.find_element(By.XPATH, '/html/body/div[3]/div[2]/div[2]/div[3]/div/table/tbody/tr/td[1]/div/div[3]/div[1]/div/div[2]')\n",
    "        comment_text = element.text\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, '/html/body/div[3]/div[2]/div[2]/div[3]/div/table/tbody/tr/td[1]/div/div[3]/div[2]/div[1]/h2/span')\n",
    "            has_attachments = (element.text == \"Attachments\")\n",
    "        except NoSuchElementException:\n",
    "            has_attachments = False\n",
    "\n",
    "        result = { \n",
    "            'document_id': document_id,\n",
    "            'tracking_number': tracking_number,\n",
    "            'date_posted': date_posted,\n",
    "            'comment_text': comment_text,\n",
    "            'has_attachments': has_attachments\n",
    "        }\n",
    "\n",
    "        return result\n",
    "    \n",
    "    except TimeoutException as ex:\n",
    "        return False\n",
    "    except NoSuchElementException as ex:\n",
    "        return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def benm_driver():\n",
    "    fp = webdriver.FirefoxProfile()\n",
    "    fp.set_preference(\"http.response.timeout\", 10)\n",
    "    fp.set_preference(\"dom.max_script_run_time\", 10)\n",
    "    driver = webdriver.Firefox(firefox_profile=fp)\n",
    "    driver.implicitly_wait(10) # seconds\n",
    "    return driver\n",
    "\n",
    "def get_comments(comments):\n",
    "    conn = psycopg2.connect(database=db_settings.DB, user=db_settings.USER, password=db_settings.PASSWD, host=db_settings.HOST)\n",
    "    conn.set_session(autocommit=True)\n",
    "    cur = conn.cursor()\n",
    "    query = 'INSERT INTO comments (document_id, tracking_number, date_posted, comment, has_attachments, retrieved) VALUES (%(document_id)s, %(tracking_number)s, %(date_posted)s, %(comment_text)s, %(has_attachments)s, now());'\n",
    "    \n",
    "    driver = benm_driver()\n",
    "    \n",
    "    for comment in comments:\n",
    "        comment_values = get_comment(driver, comment['Document Detail'], comment['Document ID'])\n",
    "        if comment_values:\n",
    "            cur.execute(query, comment_values)\n",
    "            # to do: handle duplicate keys\n",
    "        else:\n",
    "            ignore_list.append(comment['Document ID'])\n",
    "            driver.quit()\n",
    "            driver = benm_driver()\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    # conn.commit() # Make the changes to the database persistent\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list of comments to download from CSV\n",
    "with open('DOCKET_DOI-2017-0002.csv', 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    comments = [row for row in reader]\n",
    "\n",
    "comments = sorted(comments, key=lambda k: int(k['Document ID'][14:])) # sort in ascneindg order\n",
    "\n",
    "# description comment\n",
    "ignore_list.append('DOI-2017-0002-0001')\n",
    "\n",
    "# duplicates\n",
    "ignore_list.append('DOI-2017-0002-24709') # duplicate tracking Number: 1k1-8wf9-5su4\n",
    "ignore_list.append('DOI-2017-0002-24749')\n",
    "ignore_list.append('DOI-2017-0002-31984')\n",
    "ignore_list.append('DOI-2017-0002-91639')\n",
    "ignore_list.append('DOI-2017-0002-64952')\n",
    "ignore_list.append('DOI-2017-0002-91832')\n",
    "ignore_list.append('DOI-2017-0002-61934')\n",
    "ignore_list.append('DOI-2017-0002-105034')\n",
    "ignore_list.append('DOI-2017-0002-30092')\n",
    "ignore_list.append('DOI-2017-0002-36651')\n",
    "ignore_list.append('DOI-2017-0002-63026')\n",
    "ignore_list.append('DOI-2017-0002-30822')\n",
    "ignore_list.append('DOI-2017-0002-94248')\n",
    "ignore_list.append('DOI-2017-0002-94323')\n",
    "ignore_list.append('DOI-2017-0002-12214')\n",
    "ignore_list.append('DOI-2017-0002-82613')\n",
    "ignore_list.append('DOI-2017-0002-14302')\n",
    "ignore_list.append('DOI-2017-0002-106094')\n",
    "ignore_list.append('DOI-2017-0002-92237')\n",
    "ignore_list.append('DOI-2017-0002-85466')\n",
    "ignore_list.append('DOI-2017-0002-18278')\n",
    "ignore_list.append('DOI-2017-0002-24722')\n",
    "ignore_list.append('DOI-2017-0002-88668')\n",
    "ignore_list.append('DOI-2017-0002-24740')\n",
    "ignore_list.append('DOI-2017-0002-90447')\n",
    "ignore_list.append('DOI-2017-0002-95787')\n",
    "ignore_list.append('DOI-2017-0002-75285')\n",
    "ignore_list.append('DOI-2017-0002-63685')\n",
    "ignore_list.append('DOI-2017-0002-75763')\n",
    "ignore_list.append('DOI-2017-0002-91019')\n",
    "ignore_list.append('DOI-2017-0002-60433')\n",
    "ignore_list.append('DOI-2017-0002-85266')\n",
    "ignore_list.append('DOI-2017-0002-91567')\n",
    "ignore_list.append('DOI-2017-0002-91285')\n",
    "ignore_list.append('DOI-2017-0002-88631')\n",
    "ignore_list.append('DOI-2017-0002-64214')\n",
    "\n",
    "\n",
    "# general errors\n",
    "ignore_list.append('DOI-2017-0002-99259')\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(database=db_settings.DB, user=db_settings.USER, password=db_settings.PASSWD, host=db_settings.HOST)\n",
    "with conn:\n",
    "    with conn.cursor() as cur:\n",
    "        query = 'SELECT document_id FROM comments;'\n",
    "        try:\n",
    "            cur.execute(query)\n",
    "            downloaded_comments = set([c[0] for c in cur.fetchall()])\n",
    "        except psycopg2.Error as e:\n",
    "            print (query)\n",
    "            print (e.pgerror)\n",
    "conn.close()\n",
    "\n",
    "print('comments in db: ' + str(len(downloaded_comments)))\n",
    "\n",
    "comments = [c for c in comments if not c['Document ID'] in downloaded_comments]\n",
    "comments = [c for c in comments if c['Document Type'] == 'PUBLIC SUBMISSIONS']\n",
    "comments = [c for c in comments if not c['Document ID'] in ignore_list]\n",
    "\n",
    "print('remaining comments: ' + str(len(comments)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download comments. This will scrape everything, but hides errors.\n",
    "\n",
    "# from multiprocessing import Process\n",
    "# from multiprocessing import Pool\n",
    "\n",
    "# n = 50 # batch size\n",
    "\n",
    "# with Pool(processes=4, maxtasksperchild=1) as pool:\n",
    "#     pool.map_async(get_comments, [comments[i:i + n] for i in range(0, len(comments), n)], chunksize=1).get(99999)\n",
    "\n",
    "\n",
    "#     pool.close()\n",
    "#     pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spawn 8 workers to scrape 5000 comments each. Repeat as necessary.\n",
    "\n",
    "from multiprocessing import Process\n",
    "\n",
    "batch_size = 5000\n",
    "\n",
    "processes = []\n",
    "\n",
    "for i in range(8):\n",
    "    processes.append(Process(target=get_comments, args=(comments[i*batch_size:((i+1)*batch_size)-1],)))\n",
    "    processes[i].start()\n",
    "\n",
    "for i in range(8):\n",
    "    processes[i].join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
